{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBa8UUaPrgaR"
   },
   "source": [
    "# Intro to Convolutional Neural Networks\n",
    "\n",
    "So far you have been working with fully connected, or densely connected networks. These networks work well for extremely well-defined problems, like with the MNIST dataset, but it isn't very good at extracting more general information about a picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "53zaUfyyrZak"
   },
   "outputs": [],
   "source": [
    "# Import the image library from keras.preprocessing.\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Import the Image and ImageChops library from the pillow library.\n",
    "from PIL import Image, ImageChops\n",
    "\n",
    "# Import TensorFlow and Keras to create the neural network.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# Import the MNIST dataset and backend as K.\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Import NumPy and Matplotlib libraries\n",
    "import numpy as mp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pM8rm5C9B9B"
   },
   "source": [
    "# Testing your Network\n",
    "Now that you've imported and setup the libraries, you'll test your densely connected network by loading the MNIST data and printing the network's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-MZB5J22ZlA"
   },
   "source": [
    "## Load the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "u-ZMxu-k2c1q"
   },
   "outputs": [],
   "source": [
    "# Load the MNIST Data\n",
    "def show_min_max(array, i):\n",
    "    random_image = array[i]\n",
    "    print(random_image.min(), random_image.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "G4pbttWj2ynP"
   },
   "outputs": [],
   "source": [
    "# Create a function that will plot a image from the dataset and display the image.\n",
    "def plot_image(array, i ,labels):\n",
    "    plt.imshow(np.squeeze(array[i]))\n",
    "    plt.title(\"Digit \" + str(labels[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qIqEGcBC3CQ2"
   },
   "outputs": [],
   "source": [
    "# Create a function called predict_image that will print the densely connected network's prediction for the image.\n",
    "def predict_image(model,x):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    \n",
    "    image_predict = model.predict(x, verbose=0)\n",
    "    print(\"Predicted Label: \", no.argmax(image_predict))\n",
    "\n",
    "    plt.imshow(np.squeeze(x))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "    return image_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "khJAKF2R3xsU"
   },
   "outputs": [],
   "source": [
    "# Create a function called plot_value_array that will plot the image and predicted value.\n",
    "def plot_value_array(predictions_array, tru_label, h):\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10),predictions_array[0], color = '#777777')\n",
    "    plt.ylim([(-1*h), h])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MLY1MPHw6KBk"
   },
   "outputs": [],
   "source": [
    "# Load the 'my_model.h5'\n",
    "model = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMIjUUqylMSE"
   },
   "source": [
    "## Testing the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "l4trq1UsnWXA"
   },
   "outputs": [],
   "source": [
    "# Load and preprocess a test image for the network.\n",
    "path = \"invertedTest.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "mo0gjebcnlPz"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'invertedTest.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the densely connected network to see its prediction for the image.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrayscale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\image_utils.py:422\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[0;32m    421\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[1;32m--> 422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    423\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'invertedTest.jpg'"
     ]
    }
   ],
   "source": [
    "# Run the densely connected network to see its prediction for the image.\n",
    "img = tf.keras.preprocessing.image.load_img(path, target_size=(28,28), color_mode = \"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "jXP3wsWCny1i"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Re-run the network to see the colors inverted.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimg_to_array(\u001b[43mimg\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "# Re-run the network to see the colors inverted.\n",
    "x = tf.keras.preprocessing.image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAn0fNghn6VQ"
   },
   "source": [
    "# Data Preparation and Fixing the Flaws\n",
    "The network can correctly predict images, but only in a very specific set of parameters. Since all of the training images are white drawings with black backgrounds, when the network tries to guess what an image with a white background is, it has a much harder time making conclusions.\n",
    "\n",
    "For the next part, you'll invert *some* of the training data so that the network is able to practice on both white backgrounds and black backgrounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKR-ToDfqVOM"
   },
   "outputs": [],
   "source": [
    "# Create variables to keep track of the number rows and columns for each image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WVY0eg1fqZwj"
   },
   "outputs": [],
   "source": [
    "# Create a variable to keep track of the number of output classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqGw18oIqbrE"
   },
   "outputs": [],
   "source": [
    "# Load the train and test data, and a backup of each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2N0eqBdVqdhr"
   },
   "outputs": [],
   "source": [
    "# Print the shape to confirm it's the right data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k96xjsCMqgUW"
   },
   "outputs": [],
   "source": [
    "# Reshape the training and test data by converting the list of pixels into a 28x28 grid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8QxUJMq7qhyE"
   },
   "outputs": [],
   "source": [
    "# Create an input_shape variable to keep track of the data's shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__-rpkj4qklD"
   },
   "outputs": [],
   "source": [
    "# Call the plot_image function to print out the 3001 image in train_images.\n",
    "\n",
    "\n",
    "# Call the show_min_max function to display the min and max values of the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNyG8pD7n7Cq"
   },
   "outputs": [],
   "source": [
    "# Invert the training data for the network to practice on white backgrounds and black backgrounds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HW9DQNVAqyj2"
   },
   "outputs": [],
   "source": [
    "# Change the image values to between 0 and 1, convert that training and test data into float32.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EPZ8Q9Qq07S"
   },
   "outputs": [],
   "source": [
    "# Divide the images by 255 to make sure that each pixel is stored as a value between 0 and 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgfxsY4bq2q7"
   },
   "outputs": [],
   "source": [
    "# With the adjusted data, call the plot_image function to print out the 3001 image in train_images.\n",
    "\n",
    "\n",
    "# With the adjusted data, call the show_min_max function to display the min and max values of the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7HFxxjrrA10"
   },
   "outputs": [],
   "source": [
    "# Employ one-hot encoding on your training labels.\n",
    "\n",
    "\n",
    "# Employ one-hot encoding on your test labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSO_sOCTrJdM"
   },
   "source": [
    "# Re-training the Network\n",
    "Now that you've prepared your data again and fixed the flaws, you'll re-train your network by importing the sequential model and adding the layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnmkUZwvt9fl"
   },
   "source": [
    "## Import Model and Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrsgaisNrOMG"
   },
   "outputs": [],
   "source": [
    "# Import the Sequential model.\n",
    "\n",
    "\n",
    "# Import the Dense and Flatten layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUr_ClSWuBNS"
   },
   "outputs": [],
   "source": [
    "# Create a variable called epochs and set the value as 10.\n",
    "\n",
    "\n",
    "# Create a new model object called model_inv using the Keras Sequential command.\n",
    "\n",
    "\n",
    "# Add a Flatten layer and pass the input shape as an argument.\n",
    "\n",
    "\n",
    "# Add a Dense layer to your network with the size of the layers in neurons and relu as the activation function.\n",
    "\n",
    "\n",
    "# Add an output layer.\n",
    "\n",
    "\n",
    "# Print a summary of your network so far.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtyz1UzjvJh9"
   },
   "source": [
    "## Compile the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PIA4ro36veUh"
   },
   "outputs": [],
   "source": [
    "# Add the compile function that calculates the loss and uses the optimizer parameter to set the optimization algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mex912gAv6AU"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2EzYVSXv8xv"
   },
   "outputs": [],
   "source": [
    "# Add the fit function and set the input data for this model so the network doesn't rely on a pattern to learn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5xpiKzXwI7c"
   },
   "source": [
    "## Analyzing the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvFKwRhTwJpY"
   },
   "outputs": [],
   "source": [
    "# Calculate the loss and accuracy of your model.\n",
    "\n",
    "\n",
    "# Print out the test accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3D7yVDjwl5b"
   },
   "source": [
    "# Testing your Network\n",
    "With your network trained, you'll test the network and print a graph and a list with the predicted ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k2CP_BPlwr56"
   },
   "outputs": [],
   "source": [
    "# Create a variable called arr to hold the network's predicted value.\n",
    "\n",
    "\n",
    "# Plot the predicted values to a graph.\n",
    "\n",
    "\n",
    "# Print the list with the predicted values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCaj3IcuwXtu"
   },
   "source": [
    "# Exporting your Model\n",
    "Finally, you'll export your model and save it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wh_vewmbwYm8"
   },
   "outputs": [],
   "source": [
    "# Export your model.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
