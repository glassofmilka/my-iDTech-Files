{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGlC9lfuJE_V"
   },
   "source": [
    "# Intro to AI Technologies\n",
    "As technology advances, new artificial intelligence-based tools and features, such as speech recognition, image recognition, virtual chat assistants, etc., are being introduced.\n",
    "\n",
    "Recently, AI technologies from OpenAI have become more popular and well-known, such as ChatGPT, an AI-based chat system. You'll use OpenAI technologies to code your own AI-based applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcA61nAWJpBh"
   },
   "source": [
    "## Importing OpenAI\n",
    "To import the OpenAI library, you'll use the keyword import to install all the packages required to use the OpenAI tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BTes7FbwH3pF"
   },
   "outputs": [],
   "source": [
    "# Import the OpenAI library\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "t7hBkgTsTe2W"
   },
   "outputs": [],
   "source": [
    "# Use the OpenAI client library to add your API key.\n",
    "client = OpenAI(\n",
    "    api_key = \"no api key here!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bm5krV4ewBhs"
   },
   "source": [
    "## Create a While Loop\n",
    "You'll create a while loop that allows the user to input prompts until they are ready to exit the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2SnGQ6LCrV2y"
   },
   "outputs": [],
   "source": [
    "# Declare a control variable called end_program and assign the value as False.\n",
    "end_program = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lkK4qX8mtEBp"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter a prompt:  jhgjh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dungeon Master: Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter a prompt:  sky color\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dungeon Master: The color of the sky is typically described as blue, but it can also appear in shades of red, orange, pink, purple, and gray depending on the time of day and weather conditions.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter a prompt:  continues this sentence into 4-5 sentences:  Variance is the modelâ€™s sensitivity to fluctuations in the data set. To reduce the variance, we need to enlarge the amount of training data that the model uses \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dungeon Master: . Another way to reduce variance is to simplify the model by using fewer features or reducing the complexity of the algorithm. Regularization techniques can also help in reducing variance by penalizing large coefficients in the model. Cross-validation can be used to evaluate the model's performance and assess if the variance has been successfully reduced. It is important to strike a balance between reducing variance and maintaining model performance to avoid underfitting.\n"
     ]
    }
   ],
   "source": [
    "# Create a while loop to set up the chatbot system.\n",
    "while not end_program:\n",
    "    get_input = input(\"enter a prompt: \")\n",
    "    if get_input.lower() == \"exit\":\n",
    "        end_program = True\n",
    "    else:\n",
    "        system_data = [\n",
    "            {\"role\": \"system\", \"content\": \".\"},\n",
    "            {\"role\": \"user\", \"content\": get_input}\n",
    "        ]\n",
    "        response = client.chat.completions.create(\n",
    "            model = \"gpt-3.5-turbo\",\n",
    "            messages = system_data\n",
    "        )\n",
    "        dungeon_master_response = response.choices[0].message.content\n",
    "        system_data.append({\"role\": \"dungeon master\", \"content\": dungeon_master_response})\n",
    "        print(\"Dungeon Master: \" + dungeon_master_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
